{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Data Challenge - Kaggle - Summary Source Prediction\n"
      ],
      "metadata": {
        "id": "mGj0rpIYBSHs"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "rsPHwGL7TjuG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1ec6d1f5-ab3b-47a8-c096-49f00b4db01a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.17.0)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,>=0.11.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.11.6)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.6.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.11.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.5)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.4.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.63.0)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.49)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (3.10.0.2)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.7)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.7.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.10.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.1.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: imbalanced-learn in /usr/local/lib/python3.7/dist-packages (0.8.1)\n",
            "Requirement already satisfied: scipy>=0.19.1 in /usr/local/lib/python3.7/dist-packages (from imbalanced-learn) (1.4.1)\n",
            "Requirement already satisfied: scikit-learn>=0.24 in /usr/local/lib/python3.7/dist-packages (from imbalanced-learn) (1.0.2)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.7/dist-packages (from imbalanced-learn) (1.21.5)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from imbalanced-learn) (1.1.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.24->imbalanced-learn) (3.1.0)\n",
            "Requirement already satisfied: timebudget in /usr/local/lib/python3.7/dist-packages (0.7.1)\n"
          ]
        }
      ],
      "source": [
        "! pip install transformers\n",
        "! pip install imbalanced-learn\n",
        "! pip install timebudget"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "hqnHF8wCTtg-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "54b70d9a-df68-4d72-914a-e451b0b44462"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "1.10.0+cu111\n",
            "4.17.0\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import json, re\n",
        "import uuid\n",
        "\n",
        "from tqdm import tqdm_notebook\n",
        "\n",
        "try:\n",
        "    from collections import OrderedDict\n",
        "except ImportError:\n",
        "    from ordereddict import OrderedDict\n",
        "\n",
        "# Torch, Sklearn imports\n",
        "from sklearn.model_selection import train_test_split\n",
        "import torch\n",
        "import torch.optim as optim\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.autograd import Variable\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.optim import AdamW\n",
        "\n",
        "\n",
        "\n",
        "## NLP libs\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "\n",
        "from nltk import download\n",
        "import gensim\n",
        "\n",
        "## PyTorch Transformer\n",
        "import transformers\n",
        "\n",
        "## Roberta\n",
        "from transformers import RobertaModel, RobertaTokenizer,  TFRobertaModel\n",
        "from transformers import RobertaForSequenceClassification, RobertaConfig\n",
        "\n",
        "from timebudget import timebudget\n",
        "timebudget.report_atexit()  # Generate report when the program exits\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "from nltk.corpus import stopwords\n",
        "stop_words = set(stopwords.words('english'))\n",
        "# stopwords = {\"ourselves\", \"hers\", \"between\", \"yourself\", \"but\", \"again\", \"there\", \"about\", \"once\", \"during\", \"out\", \"very\", \"having\", \"with\", \"they\", \"own\", \"an\", \"be\", \"some\", \"for\", \"do\", \"its\", \"yours\", \"such\", \"into\", \"of\", \"most\", \"itself\", \"other\", \"off\", \"is\", \"s\", \"am\", \"or\", \"who\", \"as\", \"from\", \"him\", \"each\", \"the\", \"themselves\", \"until\", \"below\", \"are\", \"we\", \"these\", \"your\", \"his\", \"through\", \"don\", \"nor\", \"me\", \"were\", \"her\", \"more\", \"himself\", \"this\", \"down\", \"should\", \"our\", \"their\", \"while\", \"above\", \"both\", \"up\", \"to\", \"ours\", \"had\", \"she\", \"all\", \"no\", \"when\", \"at\", \"any\", \"before\", \"them\", \"same\", \"and\", \"been\", \"have\", \"in\", \"will\", \"on\", \"does\", \"yourselves\", \"then\", \"that\", \"because\", \"what\", \"over\", \"why\", \"so\", \"can\", \"did\", \"not\", \"now\", \"under\", \"he\", \"you\", \"herself\", \"has\", \"just\", \"where\", \"too\", \"only\", \"myself\", \"which\", \"those\", \"i\", \"after\", \"few\", \"whom\", \"t\", \"being\", \"if\", \"theirs\", \"my\", \"against\", \"a\", \"by\", \"doing\", \"it\", \"how\", \"further\", \"was\", \"here\", \"than\"}\n",
        "print(torch.__version__)\n",
        "print(transformers.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "kutMnsIOVR7X",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "66a0fe22-fb42-4d6b-eab1-a72e5df86779"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                            document  \\\n",
            "0  Two GOP presidential hopefuls - Ted Cruz and B...   \n",
            "1  The Tesla Model S P85D's 'insane mode' may be ...   \n",
            "2  MI5 has issued an alert over the threat posed ...   \n",
            "3  A new video that shows homeless people reading...   \n",
            "4  Aston Villa may be gearing up for an FA Cup se...   \n",
            "\n",
            "                                             summary  label  \n",
            "0  Ted Cruz and Ben Carson want the charity to re...      1  \n",
            "1  latvia-based drive eo has created a vehicle, n...      0  \n",
            "2  Alert issued over rogue workers in nuclear , t...      1  \n",
            "3  A short film highlights the nasty things peopl...      1  \n",
            "4  tim sherwood replied to a letter from charlie ...      0  \n"
          ]
        }
      ],
      "source": [
        "dataset = pd.read_json('./train_set.json')\n",
        "print(dataset.head(5))\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "train_dataset, validation_dataset = train_test_split(dataset, test_size=0.2, random_state=42, stratify=dataset['label'])\n",
        "\n"
      ],
      "metadata": {
        "id": "3oR7YBOsfvUe"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "RbEYE4pWUGmY"
      },
      "outputs": [],
      "source": [
        "# Model with classifier layers on top of RoBERTa\n",
        "class ROBERTAClassifier(torch.nn.Module):\n",
        "    def __init__(self, dropout_rate=0.3):\n",
        "        super(ROBERTAClassifier, self).__init__()\n",
        "        \n",
        "        self.roberta = RobertaModel.from_pretrained('roberta-base')\n",
        "        self.d1 = torch.nn.Dropout(dropout_rate)\n",
        "        self.l1 = torch.nn.Linear(768, 64)\n",
        "        self.bn1 = torch.nn.LayerNorm(64)\n",
        "        self.d2 = torch.nn.Dropout(dropout_rate)\n",
        "        self.l2 = torch.nn.Linear(64, 1)\n",
        "        self.sigmoid = torch.nn.Sigmoid()\n",
        "        \n",
        "    def forward(self, input_ids, attention_mask):\n",
        "\n",
        "        _, x = self.roberta(input_ids=input_ids, attention_mask=attention_mask, return_dict=False)\n",
        "\n",
        "        x = self.d1(x)\n",
        "        x = self.l1(x)\n",
        "        x = self.bn1(x)\n",
        "        x = torch.nn.Tanh()(x)\n",
        "        x = self.d2(x)\n",
        "        x = self.l2(x)\n",
        "        x = self.sigmoid(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "7uFkKhvVUXRz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b63ac244-2ef9-429e-cb44-1a88ecb44f68"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.bias', 'lm_head.dense.bias', 'lm_head.decoder.weight', 'lm_head.dense.weight']\n",
            "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        }
      ],
      "source": [
        "model = ROBERTAClassifier()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "bxcq5DnWb_pJ"
      },
      "outputs": [],
      "source": [
        "tokenizer = RobertaTokenizer.from_pretrained('roberta-base')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "TqXBD2wpYGyB"
      },
      "outputs": [],
      "source": [
        "def prepare_features(summary, doc, zero_pad = False, max_seq_length = 512):\n",
        "    \n",
        "    doc_tokens = tokenizer.encode_plus(text=doc, add_special_tokens=True)\n",
        "    summary_tokens = tokenizer.encode_plus(text=summary, add_special_tokens=True)\n",
        "\n",
        "    #Get the words in the summary that appear in the document\n",
        "    words_in_doc = [t for t in summary_tokens['input_ids'][1:-1] if t in doc_tokens['input_ids'][1:-1]]\n",
        "\n",
        "    if words_in_doc:\n",
        "      enc_text = tokenizer.encode_plus(text=summary, text_pair=words_in_doc, add_special_tokens=True, max_length=512, padding='max_length', truncation=True)    \n",
        "    else:\n",
        "      enc_text = tokenizer.encode_plus(text=summary, add_special_tokens=True, max_length=512, padding='max_length', truncation=True)\n",
        "\n",
        "    return enc_text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "eT9JJrH15ZA4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "37986127-2b96-4378-f7df-4b267d5a0c71"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Token indices sequence length is longer than the specified maximum sequence length for this model (807 > 512). Running this sequence through the model will result in indexing errors\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "512\n"
          ]
        }
      ],
      "source": [
        "doc = \"Father-of-four Gavin Thorman , 36 , was kingpin of a violent drugs gang . Drugs worth Â£ 200,000 seized by police following five year investigation . Planned to spend ill-gotten money on new teeth , liposuction and a facelift . He has been jailed for 12 years after admitting conspiracy to supply drugs along with 25 other defendants involved in the north Wales-based group . Gavin Thorman , 36 , of no fixed abode but formerly of Caernarfon , pleaded guilty to conspiring to supply cocaine and cannabis - 12 years . James Dylan Davies , 41 , of Cae Mur , Caernarfon , guilty to supplying cocaine - jailed eight years and six months . Richard Broadley , 34 , formerly of Caernarfon and now of Tarporley Close , Stockport , guilty to supplying cocaine and cannabis - jailed six years and eight months . Adam Roberts , 33 , of Lon Eilian , Caernarfon , guilty to supplying cocaine and cannabis - jailed for eight years . Christopher Taylor , 29 , of Pool Street , Caernarfon , guilty to supplying cocaine and cannabis - jailed for eight years and three months . Dylan Rees Hughes , 30 , of Glan Peris , Caernarfon , guilty to supplying cocaine and cannabis - jailed for nine years . Jonathan White , 32 , of Caernarfon , pleaded guilty to supplying cannabis and having an imitation gun , found guilty of supplying cocaine after a trial - 11 years . Gavin Rees Hughes , 29 , of Ty 'n Lon , Llandwrog , Caernarfon , guilty to supplying cocaine - six years and eight months . Martin Taylor , 26 , of Pool Street , Caernarfon , guilty to supplying cannabis - 40 months . Gethin Ellis , 23 , of Cae Bold , Caernarfon , guilty to supplying cocaine and cannabis - four years . Paul Hughes , 36 , of Lon Nant , Caernarfon , guilty to supplying cocaine and cannabis - four years and eight months . Martin Shaw , 32 , of Llanberis Road , Caernarfon , guilty to supplying cannabis - 20 months . Dawn Williams , 47 , of Lon Eilian , Caernarfon , allowing premises to be used for supply of cocaine and cannabis - 14 months . Julian Williams , 40 , of Lon Eilian , Caernarfon , guilty to allowing premises to be used for supply of cocaine and cannabis - 40 weeks . Yasmin Owen , 25 , of Church Drive , Caernarfon , guilty to money laundering - 12 months . Ryan Williams , 34 , of Caer Saint , Caernarfon , entering arrangement concerning criminal property - three and a half years . Nicole Herbert , 30 , of Llanddeiniolen , Caernarfon , guilty to money laundering - 10 months suspended for 18 months . Rizwan Hussain , 28 , of Rochdale and formerly of Caernarfon , found guilty of supplying cannabis after trial - six years . James Whitworth , 30 , of Manchester , pleaded guilty to cannabis , found guilty of supplying cocaine after trial - 12 years . Anthony Ferguson , 20 , of Tweedle Hill Road , Blackley , Manchester , guilty of supplying cocaine and cannabis - six years and eight months . Gregory Appleby , 20 , of Bromfield Paark , Middleton , Manchester , guilty of supplying cannabis - two years . Ian Ogden , 26 , of Hesford Avenue , Moston , Manchester , guilty to supplying cannabis - 16 months . Samuel Hughes , 34 , of White Moss Road , Blackley , Manchester , guilty to supplying cannabis - 18 months . Jake Crookes , 23 , of Selston Road , Blackley , Manchester , guilty to supplying cannabis - 16 months . Patrick Tynan , 23 , of Alconbury Walk , Blackley , Manchester , guilty to supplying cocaine and cannabis - four years . Anthony Hunt , 30 , of Rudston Avenue , Manchester , guilty to supplying cannabis - 16 months .\"\n",
        "summary = \"Father-of-four, 36 , violent drugs gang.\"\n",
        "example = prepare_features(summary, doc)\n",
        "\n",
        "print(len(example['input_ids']))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "8fPD0Ng_Wj1c"
      },
      "outputs": [],
      "source": [
        "#Class to prepare X and Y data\n",
        "class Intents(Dataset):\n",
        "    def __init__(self, dataframe, testing=False):\n",
        "        self.len = len(dataframe)\n",
        "        self.data = dataframe\n",
        "        self.testing = testing\n",
        "        \n",
        "    def __getitem__(self, index):\n",
        "\n",
        "        summary = self.data['summary'].iloc[index]\n",
        "        doc = self.data['document'].iloc[index]\n",
        "\n",
        "        X = prepare_features(summary, doc)\n",
        "\n",
        "        if self.testing:\n",
        "          return np.array(X['input_ids']), np.array(X['attention_mask'])\n",
        "\n",
        "        y = self.data['label'].iloc[index]\n",
        "        \n",
        "        return np.array(X['input_ids']), np.array(X['attention_mask']), np.array(y)\n",
        "    \n",
        "    def __len__(self):\n",
        "        return self.len"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "g6TIXi_eW-rQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4ad9beeb-346f-40b3-fb0c-2af99de7965f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TRAIN Dataset: (6400, 3)\n",
            "VALIDATION Dataset: (1600, 3)\n"
          ]
        }
      ],
      "source": [
        "print(\"TRAIN Dataset: {}\".format(train_dataset.shape))\n",
        "print(\"VALIDATION Dataset: {}\".format(validation_dataset.shape))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "JoiBbjl8Xsyz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4061d26c-0c6a-43f2-8f2a-546ac9e460c3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "6400\n"
          ]
        }
      ],
      "source": [
        "training_set = Intents(train_dataset)\n",
        "print(len(training_set))\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "validation_set = Intents(validation_dataset)\n",
        "\n",
        "x, m, y = training_set.__getitem__(820)\n",
        "print(x.shape)\n",
        "print(m.shape)\n",
        "print(y.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_eDkrwfcgCeS",
        "outputId": "c236d159-07ea-4542-9c64-26deb239f733"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1012 > 512). Running this sequence through the model will result in indexing errors\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(512,)\n",
            "(512,)\n",
            "()\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "gjlr63wGX_Tl"
      },
      "outputs": [],
      "source": [
        "\n",
        "### Dataloaders Parameters\n",
        "params = {'batch_size': 8}\n",
        "\n",
        "training_loader = DataLoader(training_set, **params)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "validation_loader = DataLoader(validation_set, **params)\n"
      ],
      "metadata": {
        "id": "wuTNLJS7nVhj"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "blkQnNiyj1NQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fc008577-f2da-4f28-dada-7cec68d77bff"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU is AVAILABLE!ðŸ¤˜ðŸ™ŒðŸ’ª\n"
          ]
        }
      ],
      "source": [
        "loss_function = nn.BCEWithLogitsLoss()\n",
        "learning_rate = 1e-5\n",
        "optimizer = optim.AdamW(params=model.parameters(), lr=learning_rate)\n",
        "if torch.cuda.is_available():\n",
        "    print(\"GPU is AVAILABLE!ðŸ¤˜ðŸ™ŒðŸ’ª\")\n",
        "    model = model.cuda()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "SS6sQ6GhYvcg"
      },
      "outputs": [],
      "source": [
        "@timebudget\n",
        "def train(model, epochs):\n",
        "  max_epochs = epochs\n",
        "  model = model.train()\n",
        "  for epoch in tqdm_notebook(range(max_epochs)):\n",
        "      print(\"EPOCH -- {}\".format(epoch))\n",
        "      correct = 0\n",
        "      total = 0\n",
        "      for i, (ids, attention_mask, labels) in enumerate(training_loader):\n",
        "\n",
        "\n",
        "          optimizer.zero_grad()\n",
        "\n",
        "          if torch.cuda.is_available():\n",
        "              ids = ids.cuda()\n",
        "              attention_mask = attention_mask.cuda()\n",
        "              labels = labels.cuda()\n",
        "\n",
        "\n",
        "          output = model.forward(ids, attention_mask=attention_mask)\n",
        "\n",
        "          loss = loss_function(output, labels.float().unsqueeze(1))\n",
        "          loss.backward()\n",
        "          optimizer.step()\n",
        "\n",
        "          predicted = torch.round(output).squeeze(1).int()\n",
        "          total += labels.size(0)\n",
        "          correct += (predicted.cpu() == labels.cpu()).sum()\n",
        "          accuracy = 100.00 * correct.numpy() / total\n",
        "\n",
        "          if i%100 == 0:\n",
        "              print('Iteration: {}. Loss: {}. Accuracy: {}.%'.format(i, loss.item(), accuracy))\n",
        "\n",
        "      print('Finished batch with: {}. Loss: {}. Accuracy: {}%'.format(i, loss.item(), accuracy))\n",
        "  \n",
        "  return \"Training finished!\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "HBS4KSZeYx_m",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 730,
          "referenced_widgets": [
            "0f390c93110847fe961834e2961f2cb7",
            "fda0e521b4ad4ac989f5453636bbf6ad",
            "0d9c46f16ad346a5959e3b2ce738b100",
            "871f71b75aa4458ab09dc7074446822f",
            "40ef8f46d2424344a2791bbdc92a585d",
            "c411d624ea9e4d4ca9a8bc7aa138f9df",
            "d638523a593d40be9ae327276198d58f",
            "3008aabbaf1e401e9044b86816bac5e3",
            "f5c1807f637a40ae9a38dc5c8d0f4a44",
            "56ac16db757846e8b8bf4f50257d53a6",
            "0f99a37418274cdd8bf2ef2618dbf7d6"
          ]
        },
        "outputId": "d471187f-7f36-49ab-d89a-a290b0c976ea"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/3 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0f390c93110847fe961834e2961f2cb7"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH -- 0\n",
            "Iteration: 0. Loss: 0.7434123158454895. Accuracy: 50.0.%\n",
            "Iteration: 100. Loss: 0.650188684463501. Accuracy: 54.33168316831683.%\n",
            "Iteration: 200. Loss: 0.5718940496444702. Accuracy: 68.28358208955224.%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration: 300. Loss: 0.6606975793838501. Accuracy: 65.19933554817275.%\n",
            "Iteration: 400. Loss: 0.7080792188644409. Accuracy: 61.97007481296758.%\n",
            "Iteration: 500. Loss: 0.5730767250061035. Accuracy: 64.74550898203593.%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration: 600. Loss: 0.5772373676300049. Accuracy: 67.42928452579035.%\n",
            "Iteration: 700. Loss: 0.5752332210540771. Accuracy: 69.56134094151213.%\n",
            "Finished batch with: 799. Loss: 0.5772653818130493. Accuracy: 72.109375%\n",
            "EPOCH -- 1\n",
            "Iteration: 0. Loss: 0.561012864112854. Accuracy: 87.5.%\n",
            "Iteration: 100. Loss: 0.5740878582000732. Accuracy: 80.56930693069307.%\n",
            "Iteration: 200. Loss: 0.4730437397956848. Accuracy: 83.76865671641791.%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration: 300. Loss: 0.48512861132621765. Accuracy: 85.00830564784053.%\n",
            "Iteration: 400. Loss: 0.5678195953369141. Accuracy: 85.81670822942644.%\n",
            "Iteration: 500. Loss: 0.5707317590713501. Accuracy: 86.60179640718563.%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration: 600. Loss: 0.5725660920143127. Accuracy: 87.14642262895175.%\n",
            "Iteration: 700. Loss: 0.5665661692619324. Accuracy: 87.55349500713267.%\n",
            "Finished batch with: 799. Loss: 0.5224918127059937. Accuracy: 88.15625%\n",
            "EPOCH -- 2\n",
            "Iteration: 0. Loss: 0.5193344354629517. Accuracy: 100.0.%\n",
            "Iteration: 100. Loss: 0.566765308380127. Accuracy: 90.47029702970298.%\n",
            "Iteration: 200. Loss: 0.47073253989219666. Accuracy: 91.41791044776119.%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration: 300. Loss: 0.6271938681602478. Accuracy: 91.15448504983388.%\n",
            "Iteration: 400. Loss: 0.5630619525909424. Accuracy: 90.74189526184539.%\n",
            "Iteration: 500. Loss: 0.6392901539802551. Accuracy: 90.91816367265469.%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration: 600. Loss: 0.6424785256385803. Accuracy: 90.91098169717138.%\n",
            "Iteration: 700. Loss: 0.5631157755851746. Accuracy: 90.5848787446505.%\n",
            "Finished batch with: 799. Loss: 0.5389032363891602. Accuracy: 91.015625%\n",
            "train took 1227.982sec\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Training finished!'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "train(model, 3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "Q1KWIkrJacw9"
      },
      "outputs": [],
      "source": [
        "torch.save(model.state_dict(), './mymodel.pt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "L0MCaptvbhes",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8a70a538-dd43-4b60-e600-78ca5b418b4d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ROBERTAClassifier(\n",
              "  (roberta): RobertaModel(\n",
              "    (embeddings): RobertaEmbeddings(\n",
              "      (word_embeddings): Embedding(50265, 768, padding_idx=1)\n",
              "      (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
              "      (token_type_embeddings): Embedding(1, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): RobertaEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): RobertaPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (d1): Dropout(p=0.3, inplace=False)\n",
              "  (l1): Linear(in_features=768, out_features=64, bias=True)\n",
              "  (bn1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
              "  (d2): Dropout(p=0.3, inplace=False)\n",
              "  (l2): Linear(in_features=64, out_features=1, bias=True)\n",
              "  (sigmoid): Sigmoid()\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "model.load_state_dict(torch.load('./mymodel.pt'))\n",
        "model.eval()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "REEdz_otD-pq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "884311b8-bff9-4612-f5ec-7e5a88c76365"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration: 0. Accuracy: 87.5%\n",
            "Iteration: 100. Accuracy: 93.1930693069307%\n",
            "Final Accuracy:  93.3125\n"
          ]
        }
      ],
      "source": [
        "#Validation\n",
        "correct = 0\n",
        "total = 0\n",
        "for i, (ids, attention_mask, labels) in enumerate(validation_loader):\n",
        "    if torch.cuda.is_available():\n",
        "        ids = ids.cuda()\n",
        "        attention_mask = attention_mask.cuda()\n",
        "        labels = labels.cuda()\n",
        "    \n",
        "    output = model.forward(ids,attention_mask=attention_mask)\n",
        "\n",
        "    predicted = torch.round(output).squeeze(1).int()\n",
        "    total += labels.size(0)\n",
        "    correct += (predicted.cpu() == labels.cpu()).sum()\n",
        "    accuracy = 100.00 * correct.numpy() / total\n",
        "\n",
        "    if i%100 == 0:      \n",
        "        print('Iteration: {}. Accuracy: {}%'.format(i, accuracy))\n",
        "\n",
        "\n",
        "accuracy = 100.00 * correct.numpy() / total\n",
        "print('Final Accuracy: ', accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "da8LUm_5og5z",
        "outputId": "e25f19ad-cb61-44f0-cca3-b8795e888c77"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total 1600\n",
            "correct:  tensor(1493)\n"
          ]
        }
      ],
      "source": [
        "print('total', total)\n",
        "print('correct: ', correct)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J5OW0-dGdWHF",
        "outputId": "bc3b3201-01e0-4e46-a8bc-0386cc8a6a62"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3200\n"
          ]
        }
      ],
      "source": [
        "#Testing\n",
        "test_dataset = pd.read_json('./test_set.json')\n",
        "print(len(test_dataset))\n",
        "testing_set = Intents(test_dataset, testing=True)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "KeLMb-eqidDj"
      },
      "outputs": [],
      "source": [
        "params = {'batch_size': 8}\n",
        "testing_loader = DataLoader(testing_set, **params)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2tcHYWOdka4S",
        "outputId": "1e0f0be9-e34e-49f1-c063-d1ce47f9860b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "400\n"
          ]
        }
      ],
      "source": [
        "print(len(testing_loader))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IXBladsciq67",
        "outputId": "6846f6e3-0d0f-4dff-a0c2-99a18e152a4f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1918 > 512). Running this sequence through the model will result in indexing errors\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration: 0.\n",
            "Iteration: 100.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration: 200.\n",
            "Iteration: 300.\n"
          ]
        }
      ],
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "all_predicted = []\n",
        "for i, (ids, attention_mask) in enumerate(testing_loader):\n",
        "    if torch.cuda.is_available():\n",
        "        ids = ids.cuda()\n",
        "        attention_mask = attention_mask.cuda()\n",
        "\n",
        "    output = model.forward(ids,attention_mask=attention_mask)\n",
        "\n",
        "    predicted = torch.round(output).squeeze(1).int()\n",
        "    all_predicted.extend(predicted.cpu().tolist())\n",
        "\n",
        "    if i%100 == 0:      \n",
        "        print('Iteration: {}.'.format(i))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hviGWs-2lvJG",
        "outputId": "f04a295d-c376-46e8-edc4-838548b5a04c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3200\n"
          ]
        }
      ],
      "source": [
        "print(len(all_predicted))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YnKXWgJYjEMU"
      },
      "outputs": [],
      "source": [
        "import csv\n",
        "# Write predictions to a file\n",
        "with open(\"submission.csv\", \"w\") as pred:\n",
        "    csv_out = csv.writer(pred)\n",
        "    csv_out.writerow(['id','label'])\n",
        "    for i, row in enumerate(all_predicted):\n",
        "        csv_out.writerow([i, row])"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "machine_shape": "hm",
      "name": "NLP-second-version.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0f390c93110847fe961834e2961f2cb7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_fda0e521b4ad4ac989f5453636bbf6ad",
              "IPY_MODEL_0d9c46f16ad346a5959e3b2ce738b100",
              "IPY_MODEL_871f71b75aa4458ab09dc7074446822f"
            ],
            "layout": "IPY_MODEL_40ef8f46d2424344a2791bbdc92a585d"
          }
        },
        "fda0e521b4ad4ac989f5453636bbf6ad": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c411d624ea9e4d4ca9a8bc7aa138f9df",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_d638523a593d40be9ae327276198d58f",
            "value": "100%"
          }
        },
        "0d9c46f16ad346a5959e3b2ce738b100": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3008aabbaf1e401e9044b86816bac5e3",
            "max": 3,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f5c1807f637a40ae9a38dc5c8d0f4a44",
            "value": 3
          }
        },
        "871f71b75aa4458ab09dc7074446822f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_56ac16db757846e8b8bf4f50257d53a6",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_0f99a37418274cdd8bf2ef2618dbf7d6",
            "value": " 3/3 [20:27&lt;00:00, 408.75s/it]"
          }
        },
        "40ef8f46d2424344a2791bbdc92a585d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c411d624ea9e4d4ca9a8bc7aa138f9df": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d638523a593d40be9ae327276198d58f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3008aabbaf1e401e9044b86816bac5e3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f5c1807f637a40ae9a38dc5c8d0f4a44": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "56ac16db757846e8b8bf4f50257d53a6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0f99a37418274cdd8bf2ef2618dbf7d6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}